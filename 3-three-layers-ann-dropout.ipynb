{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import h5py\n",
    "import scipy\n",
    "import random\n",
    "import scipy.io as scio\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from tensorflow.python.framework import ops\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "\n",
    "def max_min_normalization(data_array):\n",
    "    rows = data_array.shape[0]\n",
    "    cols = data_array.shape[1]\n",
    "    \n",
    "    temp_array = np.zeros((rows,cols))\n",
    "    col_min = data_array.min(axis=0)\n",
    "    col_max = data_array.max(axis=0)\n",
    "\n",
    "    for i in range(0,rows,1):\n",
    "        for j in range(0,cols,1):\n",
    "            temp_array[i][j] = (data_array[i][j]-col_min[j])/(col_max[j]-col_min[j])\n",
    "    return temp_array\n",
    "\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (100, 7238)\n",
      "train label shape: (52, 7238)\n",
      "test data shape: (100, 1809)\n",
      "test label shape: (52, 1809)\n"
     ]
    }
   ],
   "source": [
    "\"下载数据和标签\"\n",
    "f = scio.loadmat('db1.mat')\n",
    "data  = f['features'][:,0:100]\n",
    "label = f['features'][:,100] \n",
    "\n",
    "\"随机打乱数据和标签\"\n",
    "N = data.shape[0]\n",
    "index = np.random.permutation(N)\n",
    "data  = data[index,:]\n",
    "label = label[index]\n",
    "\n",
    "\"对数据特征归一化\"\n",
    "data = max_min_normalization(data)\n",
    "\n",
    "\"将label的数据类型改成int,将label的数字都减1\"\n",
    "label = label.astype(int)\n",
    "label = label - 1\n",
    "\n",
    "\"转换标签为one-hot\"\n",
    "label = label.reshape((1,label.shape[0]))\n",
    "label = convert_to_one_hot(label,52)\n",
    "data = data.T\n",
    "\n",
    "\"生成训练样本及标签、测试样本及标签\"\n",
    "num_train = round(N*0.8)\n",
    "num_test  = N-num_train\n",
    "\n",
    "train_data  = data[:,0:num_train]\n",
    "test_data   = data[:,num_train:N]\n",
    "train_label = label[:,0:num_train]\n",
    "test_label  = label[:,num_train:N]\n",
    "\n",
    "print(\"train data shape:\",train_data.shape)\n",
    "print(\"train label shape:\",train_label.shape)\n",
    "print(\"test data shape:\",test_data.shape)\n",
    "print(\"test label shape:\",test_label.shape)\n",
    "\n",
    "X_train = train_data\n",
    "Y_train = train_label\n",
    "X_test  = test_data\n",
    "Y_test  = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-1、创建占位符\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "\n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "\n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "\n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32, shape = [n_x, None])\n",
    "    Y = tf.placeholder(tf.float32, shape = [n_y, None])\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    \n",
    "    return X, Y, keep_prob\n",
    "\n",
    "\n",
    "# 1-2、初始化参数\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [200, 100]\n",
    "                        b1 : [200, 1]\n",
    "                        W2 : [150, 200]\n",
    "                        b2 : [150, 1]\n",
    "                        W3 : [52, 150]\n",
    "                        b3 : [52, 1]\n",
    "\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    tf.set_random_seed(1)       # so that your \"random\" numbers match ours\n",
    "\n",
    "    W1 = tf.get_variable(\"W1\", [160,100],  initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [160,1],    initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [120,160],  initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [120,1],    initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [52,120],   initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [52,1],     initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "# 1-3、TensorFlow中的前向传播\n",
    "# tf中前向传播停止在z3，是因为tf中最后的线性层输出是被作为输入计算loss，不需要a3\n",
    "def forward_propagation(X, parameters, keep_prob):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "\n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "\n",
    "  \n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    \n",
    "    A2_drop = tf.nn.dropout(A2, keep_prob)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2_drop),b3)\n",
    "    A3 = Z3\n",
    "  \n",
    "    return A3\n",
    "\n",
    "# 1-4、计算成本函数\n",
    "def compute_cost(A3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "\n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "\n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(A3)\n",
    "    labels = tf.transpose(Y)\n",
    "\n",
    "    # 函数输入：shape =（样本数，类数）\n",
    "    # tf.reduce_mean()\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-6、建立模型\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 3001, minibatch_size = 32, print_cost = True):\n",
    "\n",
    "    ops.reset_default_graph()      # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)          # to keep consistent results\n",
    "    seed = 3                       # to keep consistent results\n",
    "    (n_x, m) = X_train.shape       # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]         # n_y : output size\n",
    "    costs = []                     # To keep track of the cost\n",
    "\n",
    "    X, Y ,keep_prob = create_placeholders(n_x, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    A3 = forward_propagation(X, parameters, keep_prob)\n",
    "    cost = compute_cost(A3, Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # 开始tf会话，计算tf图\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0.                           # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches \n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict = {X: minibatch_X, Y: minibatch_Y, keep_prob:0.5})\n",
    "\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "                correct_prediction = tf.equal(tf.argmax(A3), tf.argmax(Y))\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "                print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train, keep_prob: 1}))\n",
    "                print (\"Test Accuracy:\",  accuracy.eval({X: X_test, Y: Y_test, keep_prob: 1}))\n",
    "                \n",
    "            if print_cost == True and epoch % 10 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "\n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # 将parameters保存在一个变量中\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(A3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train, keep_prob:1}))\n",
    "        print (\"Test Accuracy:\",  accuracy.eval({X: X_test, Y: Y_test, keep_prob:1}))\n",
    "\n",
    "        return parameters\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 3.955180\n",
      "Train Accuracy: 0.0449019\n",
      "Test Accuracy: 0.0508568\n",
      "Cost after epoch 100: 1.616325\n",
      "Train Accuracy: 0.61937\n",
      "Test Accuracy: 0.622443\n",
      "Cost after epoch 200: 1.283699\n",
      "Train Accuracy: 0.694943\n",
      "Test Accuracy: 0.683803\n",
      "Cost after epoch 300: 1.113294\n",
      "Train Accuracy: 0.748135\n",
      "Test Accuracy: 0.716418\n",
      "Cost after epoch 400: 0.984400\n",
      "Train Accuracy: 0.780602\n",
      "Test Accuracy: 0.735213\n",
      "Cost after epoch 500: 0.914161\n",
      "Train Accuracy: 0.806715\n",
      "Test Accuracy: 0.736871\n",
      "Cost after epoch 600: 0.843988\n",
      "Train Accuracy: 0.829925\n",
      "Test Accuracy: 0.745163\n",
      "Cost after epoch 700: 0.775451\n",
      "Train Accuracy: 0.843051\n",
      "Test Accuracy: 0.754561\n",
      "Cost after epoch 800: 0.724812\n",
      "Train Accuracy: 0.861011\n",
      "Test Accuracy: 0.754008\n",
      "Cost after epoch 900: 0.673678\n",
      "Train Accuracy: 0.872479\n",
      "Test Accuracy: 0.752902\n",
      "Cost after epoch 1000: 0.659730\n",
      "Train Accuracy: 0.885051\n",
      "Test Accuracy: 0.758983\n",
      "Cost after epoch 1100: 0.612218\n",
      "Train Accuracy: 0.895275\n",
      "Test Accuracy: 0.757325\n",
      "Cost after epoch 1200: 0.577282\n",
      "Train Accuracy: 0.906328\n",
      "Test Accuracy: 0.760641\n",
      "Cost after epoch 1300: 0.552405\n",
      "Train Accuracy: 0.917519\n",
      "Test Accuracy: 0.75843\n",
      "Cost after epoch 1400: 0.529438\n",
      "Train Accuracy: 0.928295\n",
      "Test Accuracy: 0.765064\n",
      "Cost after epoch 1500: 0.490408\n",
      "Train Accuracy: 0.934098\n",
      "Test Accuracy: 0.766722\n",
      "Cost after epoch 1600: 0.475913\n",
      "Train Accuracy: 0.939762\n",
      "Test Accuracy: 0.766169\n",
      "Cost after epoch 1700: 0.447765\n",
      "Train Accuracy: 0.94819\n",
      "Test Accuracy: 0.767828\n",
      "Cost after epoch 1800: 0.433302\n",
      "Train Accuracy: 0.951782\n",
      "Test Accuracy: 0.767275\n",
      "Cost after epoch 1900: 0.408787\n",
      "Train Accuracy: 0.957032\n",
      "Test Accuracy: 0.770039\n",
      "Cost after epoch 2000: 0.396199\n",
      "Train Accuracy: 0.960486\n",
      "Test Accuracy: 0.767828\n",
      "Cost after epoch 2100: 0.382566\n",
      "Train Accuracy: 0.964078\n",
      "Test Accuracy: 0.776119\n",
      "Cost after epoch 2200: 0.368911\n",
      "Train Accuracy: 0.968223\n",
      "Test Accuracy: 0.769486\n",
      "Cost after epoch 2300: 0.357692\n",
      "Train Accuracy: 0.970572\n",
      "Test Accuracy: 0.772803\n",
      "Cost after epoch 2400: 0.343904\n",
      "Train Accuracy: 0.973197\n",
      "Test Accuracy: 0.77225\n",
      "Cost after epoch 2500: 0.326709\n",
      "Train Accuracy: 0.977204\n",
      "Test Accuracy: 0.773355\n",
      "Cost after epoch 2600: 0.315443\n",
      "Train Accuracy: 0.978309\n",
      "Test Accuracy: 0.775567\n",
      "Cost after epoch 2700: 0.308861\n",
      "Train Accuracy: 0.983145\n",
      "Test Accuracy: 0.777225\n",
      "Cost after epoch 2800: 0.296464\n",
      "Train Accuracy: 0.981763\n",
      "Test Accuracy: 0.773908\n",
      "Cost after epoch 2900: 0.297279\n",
      "Train Accuracy: 0.984664\n",
      "Test Accuracy: 0.765616\n",
      "Cost after epoch 3000: 0.280617\n",
      "Train Accuracy: 0.985908\n",
      "Test Accuracy: 0.77225\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyKD/D9UMqKuNI7E3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xed79438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.985908\n",
      "Test Accuracy: 0.77225\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parameters = model(X_train, Y_train, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
