{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import h5py\n",
    "import scipy\n",
    "import random\n",
    "import scipy.io as scio\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import time\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import SVG\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "\n",
    "def max_min_normalization(data_array):\n",
    "    rows = data_array.shape[0]\n",
    "    cols = data_array.shape[1]\n",
    "    \n",
    "    temp_array = np.zeros((rows,cols))\n",
    "    col_min = data_array.min(axis=0)\n",
    "    col_max = data_array.max(axis=0)\n",
    "\n",
    "    for i in range(0,rows,1):\n",
    "        for j in range(0,cols,1):\n",
    "            temp_array[i][j] = (data_array[i][j]-col_min[j])/(col_max[j]-col_min[j])\n",
    "    return temp_array\n",
    "\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape =  (11322, 16, 10)\n",
      "label shape =  (11322, 1)\n",
      "(11322, 16, 10, 1) (11322, 52)\n",
      " \n",
      "number of training examples = 10190\n",
      "number of test examples = 1132\n",
      "X_train shape: (10190, 16, 10, 1)\n",
      "Y_train shape: (10190, 52)\n",
      "X_test shape: (1132, 16, 10, 1)\n",
      "Y_test shape: (1132, 52)\n"
     ]
    }
   ],
   "source": [
    "\"下载数据和标签\"\n",
    "d = scio.loadmat('data1.mat')\n",
    "data  = d['data']\n",
    "label = d['label']\n",
    "print('data shape = ',data.shape)\n",
    "print('label shape = ',label.shape)\n",
    "\n",
    "\"随机打乱数据和标签\"\n",
    "N = data.shape[0]\n",
    "index = np.random.permutation(N)\n",
    "data  = data[index,:,:]\n",
    "label = label[index,:]\n",
    "\n",
    "\"对数据data升维度,并且标签 one-hot\"\n",
    "data = np.expand_dims(data, axis=3)\n",
    "label=label-1\n",
    "label = convert_to_one_hot(label,52).T\n",
    "print(data.shape, label.shape)\n",
    "\n",
    "\"选取训练样本、测试样本\"\n",
    "N = data.shape[0]\n",
    "num_train = round(N*0.9)\n",
    "num_test  = N-num_train\n",
    "\n",
    "X_train = data[0:num_train,:,:,:]\n",
    "Y_train = label[0:num_train,:]\n",
    "X_test  = data[num_train:N,:,:,:]\n",
    "Y_test  = label[num_train:N,:]\n",
    "\n",
    "print(\" \")\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_semg(input_shape=(16,10,1), classes=52):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    \"block 1\"\n",
    "    \"32 filters,  a row of the length of number of electrodes,  ReLU\"\n",
    "    X = Conv2D(filters=32, kernel_size=(1,10), strides=(1,1),padding='same', name='conv1')(X_input)\n",
    "    X = Activation('relu', name='relu1')(X)\n",
    "    \n",
    "    \"block 2\"\n",
    "    \"32 filters 3*3,  ReLU,  average pool 3*3\"\n",
    "    X = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1),padding='same', name='conv2')(X)\n",
    "    X = Activation('relu', name='relu2')(X)\n",
    "    X = AveragePooling2D((3,3), strides=(2,2), name='pool1')(X)\n",
    "    \n",
    "    \"block 3\"\n",
    "    \"64 filters 5*5,  ReLu,  average pool 3*3\"\n",
    "    X = Conv2D(filters=64, kernel_size=(5,5), strides=(1,1),padding='same', name='conv3')(X)\n",
    "    X = Activation('relu', name='relu3')(X)\n",
    "    X = AveragePooling2D((3,3), strides=(1,1), name='pool2')(X)\n",
    "    \n",
    "    \"block 4\"\n",
    "    \"64 filters 5*1,  ReLU\"\n",
    "    X = Conv2D(filters=64, kernel_size=(5,1), strides=(1,1),padding='same', name='conv4')(X)\n",
    "    X = Activation('relu', name='relu4')(X)\n",
    "    \n",
    "    \"block 5\"\n",
    "    \"filters 1*1,  softmax loss\"\n",
    "    X = Conv2D(filters=32, kernel_size=(1,1), strides=(1,1),padding='same', name='conv5')(X)\n",
    "    X = Flatten(name='flatten')(X)\n",
    "    \n",
    "    X = Dense(256,    activation='relu',    name='fc1')(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc2')(X)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=X, name='CNN_semg')\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 3.4699 - acc: 0.0977: 0s - loss: 3.4706 - acc: 0.097\n",
      "Epoch 2/50\n",
      "10190/10190 [==============================] - 14s 1ms/step - loss: 2.6670 - acc: 0.2596\n",
      "Epoch 3/50\n",
      "10190/10190 [==============================] - 12s 1ms/step - loss: 2.2667 - acc: 0.3616\n",
      "Epoch 4/50\n",
      "10190/10190 [==============================] - 11s 1ms/step - loss: 2.0363 - acc: 0.4272\n",
      "Epoch 5/50\n",
      "10190/10190 [==============================] - 11s 1ms/step - loss: 1.8261 - acc: 0.4815\n",
      "Epoch 6/50\n",
      "10190/10190 [==============================] - 11s 1ms/step - loss: 1.6929 - acc: 0.5152\n",
      "Epoch 7/50\n",
      "10190/10190 [==============================] - 11s 1ms/step - loss: 1.6029 - acc: 0.5312\n",
      "Epoch 8/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 1.4795 - acc: 0.5588\n",
      "Epoch 9/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 1.3895 - acc: 0.5877\n",
      "Epoch 10/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 1.3148 - acc: 0.6030\n",
      "Epoch 11/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 1.2626 - acc: 0.6132\n",
      "Epoch 12/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 1.1852 - acc: 0.6338\n",
      "Epoch 13/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 1.1583 - acc: 0.6394\n",
      "Epoch 14/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 1.0961 - acc: 0.6570\n",
      "Epoch 15/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 1.0459 - acc: 0.6719\n",
      "Epoch 16/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 1.0284 - acc: 0.6707\n",
      "Epoch 17/50\n",
      "10190/10190 [==============================] - 11s 1ms/step - loss: 0.9908 - acc: 0.6859\n",
      "Epoch 18/50\n",
      "10190/10190 [==============================] - 11s 1ms/step - loss: 0.9577 - acc: 0.6958\n",
      "Epoch 19/50\n",
      "10190/10190 [==============================] - 12s 1ms/step - loss: 0.9302 - acc: 0.7035\n",
      "Epoch 20/50\n",
      "10190/10190 [==============================] - 11s 1ms/step - loss: 0.8952 - acc: 0.7136\n",
      "Epoch 21/50\n",
      "10190/10190 [==============================] - 12s 1ms/step - loss: 0.8741 - acc: 0.7201\n",
      "Epoch 22/50\n",
      "10190/10190 [==============================] - 11s 1ms/step - loss: 0.8400 - acc: 0.7294\n",
      "Epoch 23/50\n",
      "10190/10190 [==============================] - 11s 1ms/step - loss: 0.8140 - acc: 0.7295: 1s - loss: 0.815\n",
      "Epoch 24/50\n",
      "10190/10190 [==============================] - 12s 1ms/step - loss: 0.7945 - acc: 0.7440\n",
      "Epoch 25/50\n",
      "10190/10190 [==============================] - 11s 1ms/step - loss: 0.7716 - acc: 0.7484: 1s - l\n",
      "Epoch 26/50\n",
      "10190/10190 [==============================] - 12s 1ms/step - loss: 0.7722 - acc: 0.7474\n",
      "Epoch 27/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.7479 - acc: 0.7565\n",
      "Epoch 28/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.7599 - acc: 0.7576\n",
      "Epoch 29/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.7291 - acc: 0.7600\n",
      "Epoch 30/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.7054 - acc: 0.7693\n",
      "Epoch 31/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.6663 - acc: 0.7814\n",
      "Epoch 32/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.6748 - acc: 0.7743\n",
      "Epoch 33/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.6620 - acc: 0.7803\n",
      "Epoch 34/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.6344 - acc: 0.7876\n",
      "Epoch 35/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.6247 - acc: 0.7924\n",
      "Epoch 36/50\n",
      "10190/10190 [==============================] - 12s 1ms/step - loss: 0.6285 - acc: 0.7906\n",
      "Epoch 37/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.6177 - acc: 0.7929\n",
      "Epoch 38/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.6191 - acc: 0.7932\n",
      "Epoch 39/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.5795 - acc: 0.8044\n",
      "Epoch 40/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.5572 - acc: 0.8182\n",
      "Epoch 41/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.5647 - acc: 0.8110\n",
      "Epoch 42/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.5621 - acc: 0.8113\n",
      "Epoch 43/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.5233 - acc: 0.8236\n",
      "Epoch 44/50\n",
      "10190/10190 [==============================] - 12s 1ms/step - loss: 0.5531 - acc: 0.8111\n",
      "Epoch 45/50\n",
      "10190/10190 [==============================] - 12s 1ms/step - loss: 0.5170 - acc: 0.8228\n",
      "Epoch 46/50\n",
      "10190/10190 [==============================] - 12s 1ms/step - loss: 0.4935 - acc: 0.8331\n",
      "Epoch 47/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.4788 - acc: 0.8390\n",
      "Epoch 48/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.4808 - acc: 0.8369\n",
      "Epoch 49/50\n",
      "10190/10190 [==============================] - 12s 1ms/step - loss: 0.4927 - acc: 0.8292\n",
      "Epoch 50/50\n",
      "10190/10190 [==============================] - 13s 1ms/step - loss: 0.4755 - acc: 0.8358\n",
      "10190/10190 [==============================] - 4s 412us/step\n",
      "Train Loss = 0.443065135326\n",
      "Train Accuracy = 0.847791952907\n",
      "1132/1132 [==============================] - 0s 413us/step\n",
      "Test Loss = 1.31954987479\n",
      "Test Accuracy = 0.685512367491\n"
     ]
    }
   ],
   "source": [
    "model = CNN_semg(input_shape = (16, 10, 1), classes = 52)  \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=50, batch_size=64)\n",
    "\n",
    "\n",
    "preds_train = model.evaluate(X_train, Y_train)\n",
    "print(\"Train Loss = \" + str(preds_train[0]))\n",
    "print(\"Train Accuracy = \" + str(preds_train[1]))\n",
    "\n",
    "preds_test  = model.evaluate(X_test, Y_test)\n",
    "print(\"Test Loss = \" + str(preds_test[0]))\n",
    "print(\"Test Accuracy = \" + str(preds_test[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 16, 10, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 16, 10, 32)        352       \n",
      "_________________________________________________________________\n",
      "relu1 (Activation)           (None, 16, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 16, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "relu2 (Activation)           (None, 16, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "pool1 (AveragePooling2D)     (None, 7, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 7, 4, 64)          51264     \n",
      "_________________________________________________________________\n",
      "relu3 (Activation)           (None, 7, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "pool2 (AveragePooling2D)     (None, 5, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 5, 2, 64)          20544     \n",
      "_________________________________________________________________\n",
      "relu4 (Activation)           (None, 5, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 5, 2, 32)          2080      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               82176     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 52)                13364     \n",
      "=================================================================\n",
      "Total params: 179,028\n",
      "Trainable params: 179,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"打印模型图层细节\"\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
