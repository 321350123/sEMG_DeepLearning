{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import h5py\n",
    "import scipy\n",
    "import random\n",
    "import scipy.io as scio\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from tensorflow.python.framework import ops\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "\n",
    "def max_min_normalization(data_array):\n",
    "    rows = data_array.shape[0]\n",
    "    cols = data_array.shape[1]\n",
    "    \n",
    "    temp_array = np.zeros((rows,cols))\n",
    "    col_min = data_array.min(axis=0)\n",
    "    col_max = data_array.max(axis=0)\n",
    "\n",
    "    for i in range(0,rows,1):\n",
    "        for j in range(0,cols,1):\n",
    "            temp_array[i][j] = (data_array[i][j]-col_min[j])/(col_max[j]-col_min[j])\n",
    "    return temp_array\n",
    "\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (100, 7238)\n",
      "train label shape: (52, 7238)\n",
      "test data shape: (100, 1809)\n",
      "test label shape: (52, 1809)\n"
     ]
    }
   ],
   "source": [
    "\"下载数据和标签\"\n",
    "f = scio.loadmat('db1.mat')\n",
    "data  = f['features'][:,0:100]\n",
    "label = f['features'][:,100] \n",
    "\n",
    "\"随机打乱数据和标签\"\n",
    "N = data.shape[0]\n",
    "index = np.random.permutation(N)\n",
    "data  = data[index,:]\n",
    "label = label[index]\n",
    "\n",
    "\"对数据特征归一化\"\n",
    "data = max_min_normalization(data)\n",
    "\n",
    "\"将label的数据类型改成int,将label的数字都减1\"\n",
    "label = label.astype(int)\n",
    "label = label - 1\n",
    "\n",
    "\"转换标签为one-hot\"\n",
    "label = label.reshape((1,label.shape[0]))\n",
    "label = convert_to_one_hot(label,52)\n",
    "data = data.T\n",
    "\n",
    "\"生成训练样本及标签、测试样本及标签\"\n",
    "num_train = round(N*0.8)\n",
    "num_test  = N-num_train\n",
    "\n",
    "train_data  = data[:,0:num_train]\n",
    "test_data   = data[:,num_train:N]\n",
    "train_label = label[:,0:num_train]\n",
    "test_label  = label[:,num_train:N]\n",
    "\n",
    "print(\"train data shape:\",train_data.shape)\n",
    "print(\"train label shape:\",train_label.shape)\n",
    "print(\"test data shape:\",test_data.shape)\n",
    "print(\"test label shape:\",test_label.shape)\n",
    "\n",
    "X_train = train_data\n",
    "Y_train = train_label\n",
    "X_test  = test_data\n",
    "Y_test  = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    X = tf.placeholder(tf.float32, shape = [n_x, None])\n",
    "    Y = tf.placeholder(tf.float32, shape = [n_y, None])\n",
    "    return X, Y\n",
    "\n",
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)     \n",
    "\n",
    "    W1 = tf.get_variable(\"W1\", [52,100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [52,1],     initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1}\n",
    "\n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "  \n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)  \n",
    "    \n",
    "    return Z1\n",
    "\n",
    "def compute_cost(Z1, Y):\n",
    "    \n",
    "    logits = tf.transpose(Z1)\n",
    "    labels = tf.transpose(Y)\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-6、建立模型\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.05,\n",
    "          num_epochs = 2000, minibatch_size = 32, print_cost = True):\n",
    "\n",
    "    ops.reset_default_graph()      # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)          # to keep consistent results\n",
    "    seed = 3                       # to keep consistent results\n",
    "    (n_x, m) = X_train.shape       # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]         # n_y : output size\n",
    "    costs = []                     # To keep track of the cost\n",
    "\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z1 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z1, Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # 开始tf会话，计算tf图\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_cost = 0.                           # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches \n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict = {X: minibatch_X, Y: minibatch_Y})\n",
    "\n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 10 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "\n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # 将parameters保存在一个变量中\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z1), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\",  accuracy.eval({X: X_test, Y: Y_test}))\n",
    "\n",
    "        return parameters\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 2.662609\n",
      "Cost after epoch 100: 1.190141\n",
      "Cost after epoch 200: 1.137198\n",
      "Cost after epoch 300: 1.096363\n",
      "Cost after epoch 400: 1.069924\n",
      "Cost after epoch 500: 1.045596\n",
      "Cost after epoch 600: 1.063913\n",
      "Cost after epoch 700: 1.039348\n",
      "Cost after epoch 800: 1.052710\n",
      "Cost after epoch 900: 1.025791\n",
      "Cost after epoch 1000: 1.021477\n",
      "Cost after epoch 1100: 0.991901\n",
      "Cost after epoch 1200: 1.007453\n",
      "Cost after epoch 1300: 1.003293\n",
      "Cost after epoch 1400: 0.993071\n",
      "Cost after epoch 1500: 0.996352\n",
      "Cost after epoch 1600: 0.996885\n",
      "Cost after epoch 1700: 0.985338\n",
      "Cost after epoch 1800: 0.985578\n",
      "Cost after epoch 1900: 0.983148\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
