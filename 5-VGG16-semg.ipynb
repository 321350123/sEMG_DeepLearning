{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import h5py\n",
    "import scipy\n",
    "import random\n",
    "import scipy.io as scio\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import time\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import SVG\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "\n",
    "def max_min_normalization(data_array):\n",
    "    rows = data_array.shape[0]\n",
    "    cols = data_array.shape[1]\n",
    "    \n",
    "    temp_array = np.zeros((rows,cols))\n",
    "    col_min = data_array.min(axis=0)\n",
    "    col_max = data_array.max(axis=0)\n",
    "\n",
    "    for i in range(0,rows,1):\n",
    "        for j in range(0,cols,1):\n",
    "            temp_array[i][j] = (data_array[i][j]-col_min[j])/(col_max[j]-col_min[j])\n",
    "    return temp_array\n",
    "\n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape =  (11322, 16, 10)\n",
      "label shape =  (11322, 1)\n",
      "(11322, 16, 10, 1) (11322, 52)\n",
      " \n",
      "number of training examples = 10190\n",
      "number of test examples = 1132\n",
      "X_train shape: (10190, 16, 10, 1)\n",
      "Y_train shape: (10190, 52)\n",
      "X_test shape: (1132, 16, 10, 1)\n",
      "Y_test shape: (1132, 52)\n"
     ]
    }
   ],
   "source": [
    "\"下载数据和标签\"\n",
    "d = scio.loadmat('data1.mat')\n",
    "data  = d['data']\n",
    "label = d['label']\n",
    "print('data shape = ',data.shape)\n",
    "print('label shape = ',label.shape)\n",
    "\n",
    "\"随机打乱数据和标签\"\n",
    "N = data.shape[0]\n",
    "index = np.random.permutation(N)\n",
    "data  = data[index,:,:]\n",
    "label = label[index,:]\n",
    "\n",
    "\"对数据data升维度,并且标签 one-hot\"\n",
    "data = np.expand_dims(data, axis=3)\n",
    "label=label-1\n",
    "label = convert_to_one_hot(label,52).T\n",
    "print(data.shape, label.shape)\n",
    "\n",
    "\"选取训练样本、测试样本\"\n",
    "N = data.shape[0]\n",
    "num_train = round(N*0.9)\n",
    "num_test  = N-num_train\n",
    "\n",
    "X_train = data[0:num_train,:,:,:]\n",
    "Y_train = label[0:num_train,:]\n",
    "X_test  = data[num_train:N,:,:,:]\n",
    "Y_test  = label[num_train:N,:]\n",
    "\n",
    "print(\" \")\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG16_semg(input_shape=(16,10,1), classes=52):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "        \n",
    "    \"block 1\"\n",
    "    X = Conv2D(filters=4, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='block1_conv1')(X_input)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Conv2D(filters=4, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='block1_conv2')(X)\n",
    "\n",
    "    \n",
    "    \"block 2\"\n",
    "    X = Conv2D(filters=8, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='block2_conv1')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Conv2D(filters=8, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='block2_conv2')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    \n",
    "    \"block 3\"\n",
    "    X = Conv2D(filters=16, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='block3_conv1')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Conv2D(filters=16, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='block3_conv2')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Conv2D(filters=16, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='block3_conv3')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = AveragePooling2D((2,2), strides=(2,2), name='block3_pool')(X)\n",
    "    \n",
    "    \"block 4\"\n",
    "    X = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='block4_conv1')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='block4_conv2')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='block4_conv3')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    \n",
    "    \"block 5\"\n",
    "    X = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='block5_conv1')(X)\n",
    "    X = BatchNormalization(axis=3)(X)    \n",
    "    X = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='block5_conv2')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), activation='relu', padding='same', name='block5_conv3')(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    \n",
    "    X = Flatten(name='flatten')(X)\n",
    "    X = Dense(256,    activation='relu',    name='fc1')(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc2')(X)\n",
    "    \n",
    "    model = Model(inputs=X_input, outputs=X, name='VGG16_semg')\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10190/10190 [==============================] - 34s 3ms/step - loss: 2.8742 - acc: 0.2731\n",
      "Epoch 2/20\n",
      "10190/10190 [==============================] - 28s 3ms/step - loss: 2.0038 - acc: 0.4411\n",
      "Epoch 3/20\n",
      "10190/10190 [==============================] - 27s 3ms/step - loss: 1.5894 - acc: 0.5358\n",
      "Epoch 4/20\n",
      "10190/10190 [==============================] - 27s 3ms/step - loss: 1.3242 - acc: 0.6010\n",
      "Epoch 5/20\n",
      "10190/10190 [==============================] - 28s 3ms/step - loss: 1.1710 - acc: 0.6455\n",
      "Epoch 6/20\n",
      "10190/10190 [==============================] - 27s 3ms/step - loss: 1.0242 - acc: 0.6813\n",
      "Epoch 7/20\n",
      "10190/10190 [==============================] - 28s 3ms/step - loss: 0.8980 - acc: 0.7182\n",
      "Epoch 8/20\n",
      "10190/10190 [==============================] - 28s 3ms/step - loss: 0.7992 - acc: 0.7424\n",
      "Epoch 9/20\n",
      "10190/10190 [==============================] - 28s 3ms/step - loss: 0.7204 - acc: 0.7740\n",
      "Epoch 10/20\n",
      "10190/10190 [==============================] - 28s 3ms/step - loss: 0.6747 - acc: 0.7837\n",
      "Epoch 11/20\n",
      "10190/10190 [==============================] - 30s 3ms/step - loss: 0.5830 - acc: 0.8097\n",
      "Epoch 12/20\n",
      "10190/10190 [==============================] - 32s 3ms/step - loss: 0.5405 - acc: 0.8224\n",
      "Epoch 13/20\n",
      "10190/10190 [==============================] - 30s 3ms/step - loss: 0.5198 - acc: 0.8316\n",
      "Epoch 14/20\n",
      "10190/10190 [==============================] - 30s 3ms/step - loss: 0.4422 - acc: 0.8578\n",
      "Epoch 15/20\n",
      "10190/10190 [==============================] - 30s 3ms/step - loss: 0.4238 - acc: 0.8612\n",
      "Epoch 16/20\n",
      "10190/10190 [==============================] - 29s 3ms/step - loss: 0.3955 - acc: 0.8692: 1s - loss: 0.3920 - acc\n",
      "Epoch 17/20\n",
      "10190/10190 [==============================] - 29s 3ms/step - loss: 0.3266 - acc: 0.8915\n",
      "Epoch 18/20\n",
      "10190/10190 [==============================] - 29s 3ms/step - loss: 0.3250 - acc: 0.8936\n",
      "Epoch 19/20\n",
      "10190/10190 [==============================] - 29s 3ms/step - loss: 0.2932 - acc: 0.9040\n",
      "Epoch 20/20\n",
      "10190/10190 [==============================] - 28s 3ms/step - loss: 0.2792 - acc: 0.9081\n",
      "10190/10190 [==============================] - 12s 1ms/step\n",
      "Train Loss = 0.285488943099\n",
      "Train Accuracy = 0.905495583894\n",
      "1132/1132 [==============================] - 1s 1ms/step\n",
      "Test Loss = 1.87626663703\n",
      "Test Accuracy = 0.591872791309\n"
     ]
    }
   ],
   "source": [
    "model = VGG16_semg(input_shape = (16, 10, 1), classes = 52)  \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=64)\n",
    "\n",
    "\n",
    "preds_train = model.evaluate(X_train, Y_train)\n",
    "print(\"Train Loss = \" + str(preds_train[0]))\n",
    "print(\"Train Accuracy = \" + str(preds_train[1]))\n",
    "\n",
    "preds_test  = model.evaluate(X_test, Y_test)\n",
    "print(\"Test Loss = \" + str(preds_test[0]))\n",
    "print(\"Test Accuracy = \" + str(preds_test[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 16, 10, 1)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 16, 10, 4)         40        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 10, 4)         16        \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 16, 10, 4)         148       \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 10, 8)         296       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 10, 8)         32        \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 10, 8)         584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 10, 8)         32        \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 10, 16)        1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 10, 16)        64        \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 10, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 10, 16)        64        \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 10, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 10, 16)        64        \n",
      "_________________________________________________________________\n",
      "block3_pool (AveragePooling2 (None, 8, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 5, 32)          4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 5, 32)          128       \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 5, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 5, 32)          128       \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 5, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 5, 32)          128       \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 5, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 8, 5, 32)          128       \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 5, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 5, 32)          128       \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 5, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8, 5, 32)          128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               327936    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 52)                13364     \n",
      "=================================================================\n",
      "Total params: 400,096\n",
      "Trainable params: 399,576\n",
      "Non-trainable params: 520\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"打印模型图层细节\"\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
